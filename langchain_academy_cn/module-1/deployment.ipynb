{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e83a41b",
   "metadata": {},
   "source": [
    "[![在 Colab 中打开](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/deployment.ipynb) [![在 LangChain Academy 中打开](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239303-lesson-8-deployment)\n",
    "\n",
    "（注：严格保留所有 Markdown 格式和链接内容，仅对按钮描述文字进行本地化翻译）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20242c4-0010-4065-89f6-0e0b16c7da6e",
   "metadata": {},
   "source": [
    "# 部署\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们构建了一个具备记忆功能的智能体：\n",
    "\n",
    "* `act`（执行） - 让模型调用特定工具\n",
    "* `observe`（观察） - 将工具输出回传给模型\n",
    "* `reason`（推理） - 让模型根据工具输出进行推理，决定下一步操作（例如调用其他工具或直接响应）\n",
    "* `persist state`（状态持久化） - 使用内存检查点机制来支持可中断的长时间对话\n",
    "\n",
    "## 目标\n",
    "\n",
    "接下来，我们将介绍如何将智能体实际部署到本地Studio环境和`LangGraph Cloud`平台。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f348498b-f277-4514-b163-fe5ed9afe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph_sdk langchain_core"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d0f4a7-82ee-4458-bd9a-e246ce2dc4ae",
   "metadata": {},
   "source": [
    "## 核心概念\n",
    "\n",
    "需要理解以下几个核心概念：\n",
    "\n",
    "`LangGraph` —\n",
    "- Python 和 JavaScript 库\n",
    "- 支持创建智能体工作流\n",
    "\n",
    "`LangGraph API` —\n",
    "- 封装图代码\n",
    "- 提供任务队列管理异步操作\n",
    "- 支持跨交互状态持久化\n",
    "\n",
    "`LangGraph Cloud` —\n",
    "- LangGraph API 的托管服务\n",
    "- 支持从 GitHub 仓库部署图\n",
    "- 提供已部署图的监控和追踪功能\n",
    "- 每个部署都有专属访问 URL\n",
    "\n",
    "`LangGraph Studio` —\n",
    "- LangGraph 应用的集成开发环境（IDE）\n",
    "- 以 API 为后端，支持图的实时测试与探索\n",
    "- 可在本地运行或云端部署\n",
    "\n",
    "`LangGraph SDK` —\n",
    "- 用于编程交互的 Python 库\n",
    "- 为本地或云端运行的图提供统一接口\n",
    "- 支持创建客户端、访问助手、线程管理和运行执行\n",
    "\n",
    "## 本地测试\n",
    "\n",
    "**⚠️ 免责声明**\n",
    "\n",
    "自视频录制后，我们已更新 Studio 使其可在本地运行并通过浏览器访问。现在这是运行 Studio 的首选方式（而非视频中展示的桌面应用）。关于本地开发服务器的文档参见[此处](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server)，本地运行 Studio 的说明参见[此处](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server)。要启动本地开发服务器，请在本模块的 `/studio` 目录下执行以下命令：\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "你将看到如下输出：\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio 界面: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API 文档: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "在浏览器中访问 Studio 界面：`https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa75ebd4-91fe-42c5-8122-c81e72133477",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b281d8-bd07-4721-922c-347838ceee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c96f353-5dc3-41c8-a3e4-6bf07ca455f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1352fa-68ad-4963-890e-c95d93570917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'config': {},\n",
       " 'metadata': {'created_by': 'system'},\n",
       " 'name': 'agent',\n",
       " 'created_at': '2025-03-04T22:57:28.424565+00:00',\n",
       " 'updated_at': '2025-03-04T22:57:28.424565+00:00',\n",
       " 'version': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9c28a0-d712-496c-b191-7d620589ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a thread for tracking the state of our run\n",
    "thread = await client.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e4177-3644-43fa-a2f1-08f73292d1a6",
   "metadata": {},
   "source": [
    "现在，我们可以通过 [`client.runs.stream`](https://langchain-ai.github.io/langgraph/concepts/low_level/#stream-and-astream) 运行我们的智能体，需要提供以下参数：\n",
    "\n",
    "* `thread_id`（线程ID）\n",
    "* `graph_id`（图ID）\n",
    "* `input`（输入内容）\n",
    "* `stream_mode`（流模式）\n",
    "\n",
    "我们将在后续模块中深入探讨流式处理机制。\n",
    "\n",
    "目前只需了解：通过设置 `stream_mode=\"values\"`，我们正在[流式传输](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/)图执行过程中每一步的完整状态值。\n",
    "\n",
    "状态数据存储在 `chunk.data` 中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65a4480-66b3-48bf-9158-191a7b8c1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Multiply 3 by 2.', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'cdbd7bd8-c476-4ad4-8ab7-4ad9e3654267', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-06c7243c-426d-4c81-a113-f1335dda5fb2', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '988cb170-f6e6-43c1-82fd-309f519abe6d', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}\n",
      "{'content': 'The result of multiplying 3 by 2 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-7bda0aa0-6895-4250-9625-18419c5dc171', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"Multiply 3 by 2.\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "        thread['thread_id'],\n",
    "        \"agent\",\n",
    "        input=input,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data['messages'][-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa8b850-750c-4054-95e4-1c457a12ec8a",
   "metadata": {},
   "source": [
    "## 云端测试\n",
    "\n",
    "我们可以通过 LangSmith 部署到云端，具体操作步骤详见[此处](https://langchain-ai.github.io/langgraph/cloud/quick_start/#deploy-from-github-with-langgraph-cloud)。\n",
    "\n",
    "### 在 GitHub 创建新仓库\n",
    "\n",
    "* 登录您的 GitHub 账户\n",
    "* 点击右上角\"+\"图标，选择`\"New repository\"`\n",
    "* 为仓库命名（例如 `langchain-academy`）\n",
    "\n",
    "### 添加 GitHub 仓库为远程源\n",
    "\n",
    "* 返回本课程开始时克隆 `langchain-academy` 的终端窗口\n",
    "* 将新建的 GitHub 仓库添加为远程源\n",
    "\n",
    "```\n",
    "git remote add origin https://github.com/your-username/your-repo-name.git\n",
    "```\n",
    "* 推送代码\n",
    "```\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "### 将 LangSmith 连接到 GitHub 仓库\n",
    "\n",
    "* 访问 [LangSmith](hhttps://smith.langchain.com/)\n",
    "* 点击左侧面板的 `deployments` 选项卡\n",
    "* 添加 `+ New Deployment`\n",
    "* 选择您为本课程创建的 GitHub 仓库（如 `langchain-academy`）\n",
    "* 将 `LangGraph API 配置文件` 指向某个 `studio` 目录\n",
    "* 例如对于模块1，使用：`module-1/studio/langgraph.json`\n",
    "* 设置 API 密钥（可直接从 `module-1/studio/.env` 文件复制）\n",
    "\n",
    "![Screenshot 2024-09-03 at 11.35.12 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fd61c93d48e5d0f47_deployment2.png)\n",
    "\n",
    "### 使用您的部署\n",
    "\n",
    "我们可以通过多种方式与部署进行交互：\n",
    "\n",
    "* 使用之前提到的 [SDK](https://langchain-ai.github.io/langgraph/cloud/quick_start/#use-with-the-sdk)\n",
    "* 通过 [LangGraph Studio](https://langchain-ai.github.io/langgraph/cloud/quick_start/#interact-with-your-deployment-via-langgraph-studio)\n",
    "\n",
    "![Screenshot 2024-08-23 at 10.59.36 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fa159a09a51d601de_deployment3.png)\n",
    "\n",
    "若要在笔记本中使用 SDK，只需确保已设置 `LANGSMITH_API_KEY`！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646ed351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda16c-c87f-4c03-b910-d647e83400b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the URL of your deployed graph\n",
    "URL = \"https://langchain-academy-8011c561878d50b1883f7ed11b32d720.default.us.langgraph.app\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefa37c0-92fe-4e80-9d5a-80a77b1e3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the agent\n",
    "agent = assistants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b810376e-f20f-443a-b1ca-d6793f358f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'created_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'updated_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'config': {},\n",
       " 'metadata': {'created_by': 'system'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32d65d84-1bcf-4af4-a7c9-55e73d6c1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Multiply 3 by 2.', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '8ea04559-f7d4-4c82-89d9-c60fb0502f21', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-b0ea5ddd-e9ba-4242-bb8c-80eb52466c76', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '1bf558e7-79ef-4f21-bb66-acafbd04677a', 'tool_call_id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'artifact': None, 'status': 'success'}\n",
      "{'content': '3 multiplied by 2 equals 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-ecc4b6ad-af15-4a85-a76c-de2ed0ed8ed9', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# We create a thread for tracking the state of our run\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"Multiply 3 by 2.\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "        thread['thread_id'],\n",
    "        \"agent\",\n",
    "        input=input,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cb34d-c3b8-4446-a7e3-5fe938abf99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}